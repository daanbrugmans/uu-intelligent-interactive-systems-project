{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 40\n",
      "Columns:\n",
      " ['Filename', 'Width', 'Height', 'Age', 'Gender', 'Valence', 'Arousal', 'Dominance', 'Peace', 'Affection', 'Esteem', 'Anticipation', 'Engagement', 'Confidence', 'Happiness', 'Pleasure', 'Excitement', 'Surprise', 'Sympathy', 'Doubt/Confusion', 'Disconnection', 'Fatigue', 'Embarrassment', 'Yearning', 'Disapproval', 'Aversion', 'Annoyance', 'Anger', 'Sensitivity', 'Sadness', 'Disquietment', 'Fear', 'Pain', 'Suffering', 'X_min', 'Y_min', 'X_max', 'Y_max', 'Arr_name', 'Crop_name']\n",
      "\n",
      "HEAD:\n",
      "                           Filename  Width  Height       Age  Gender  Valence  \\\n",
      "0    COCO_val2014_000000562243.jpg  640.0   640.0     Adult    Male      5.0   \n",
      "1  COCO_train2014_000000288841.jpg  640.0   480.0     Adult    Male      6.0   \n",
      "2    COCO_val2014_000000558171.jpg  640.0   480.0  Teenager    Male      7.0   \n",
      "3  COCO_train2014_000000369575.jpg  480.0   640.0       Kid    Male      8.0   \n",
      "4  COCO_train2014_000000213009.jpg  500.0   333.0     Adult    Male      7.0   \n",
      "5  COCO_train2014_000000462955.jpg  640.0   478.0     Adult    Male      3.0   \n",
      "6    COCO_val2014_000000168683.jpg  500.0   375.0     Adult    Male      6.0   \n",
      "7  COCO_train2014_000000186198.jpg  640.0   429.0       Kid    Male      7.0   \n",
      "8  COCO_train2014_000000006590.jpg  640.0   480.0       Kid  Female      7.0   \n",
      "9  COCO_train2014_000000144608.jpg  350.0   500.0  Teenager    Male      7.0   \n",
      "\n",
      "   Arousal  Dominance  Peace  Affection  ...  Disquietment  Fear  Pain  \\\n",
      "0      3.0        9.0    0.0        0.0  ...           0.0   0.0   0.0   \n",
      "1      4.0        7.0    0.0        0.0  ...           0.0   0.0   0.0   \n",
      "2      8.0        8.0    0.0        0.0  ...           0.0   0.0   0.0   \n",
      "3      9.0        8.0    0.0        0.0  ...           0.0   0.0   0.0   \n",
      "4      9.0       10.0    0.0        0.0  ...           0.0   0.0   0.0   \n",
      "5      6.0        8.0    1.0        0.0  ...           0.0   0.0   0.0   \n",
      "6      7.0        7.0    0.0        0.0  ...           0.0   0.0   0.0   \n",
      "7      7.0        8.0    1.0        0.0  ...           0.0   0.0   0.0   \n",
      "8      4.0        7.0    0.0        0.0  ...           0.0   0.0   0.0   \n",
      "9      7.0        6.0    0.0        0.0  ...           0.0   0.0   0.0   \n",
      "\n",
      "   Suffering  X_min  Y_min  X_max  Y_max       Arr_name             Crop_name  \n",
      "0        0.0   86.0   58.0  564.0  628.0  img_arr_0.npy  crop_arr_train_0.npy  \n",
      "1        0.0  485.0  149.0  605.0  473.0  img_arr_1.npy  crop_arr_train_1.npy  \n",
      "2        0.0  305.0   92.0  461.0  465.0  img_arr_2.npy  crop_arr_train_2.npy  \n",
      "3        0.0  221.0   63.0  448.0  372.0  img_arr_3.npy  crop_arr_train_3.npy  \n",
      "4        0.0   44.0  143.0  150.0  288.0  img_arr_4.npy  crop_arr_train_4.npy  \n",
      "5        0.0   42.0   32.0  413.0  472.0  img_arr_5.npy  crop_arr_train_5.npy  \n",
      "6        0.0  257.0   39.0  405.0  183.0  img_arr_6.npy  crop_arr_train_6.npy  \n",
      "7        0.0  336.0   80.0  494.0  327.0  img_arr_7.npy  crop_arr_train_7.npy  \n",
      "8        0.0  188.0  109.0  381.0  382.0  img_arr_8.npy  crop_arr_train_8.npy  \n",
      "9        0.0  198.0   29.0  300.0  232.0  img_arr_9.npy  crop_arr_train_9.npy  \n",
      "\n",
      "[10 rows x 40 columns]\n",
      "Train: 24639\n",
      "Val: 2397\n",
      "Test: 7279\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop_name</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crop_arr_train_0.npy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>/teamspace/studios/this_studio/.cache/kagglehu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crop_arr_train_1.npy</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>/teamspace/studios/this_studio/.cache/kagglehu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crop_arr_train_2.npy</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>/teamspace/studios/this_studio/.cache/kagglehu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crop_arr_train_3.npy</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>/teamspace/studios/this_studio/.cache/kagglehu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crop_arr_train_4.npy</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>/teamspace/studios/this_studio/.cache/kagglehu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Crop_name  Valence  Arousal  \\\n",
       "0  crop_arr_train_0.npy      5.0      3.0   \n",
       "1  crop_arr_train_1.npy      6.0      4.0   \n",
       "2  crop_arr_train_2.npy      7.0      8.0   \n",
       "3  crop_arr_train_3.npy      8.0      9.0   \n",
       "4  crop_arr_train_4.npy      7.0      9.0   \n",
       "\n",
       "                                            img_path  \n",
       "0  /teamspace/studios/this_studio/.cache/kagglehu...  \n",
       "1  /teamspace/studios/this_studio/.cache/kagglehu...  \n",
       "2  /teamspace/studios/this_studio/.cache/kagglehu...  \n",
       "3  /teamspace/studios/this_studio/.cache/kagglehu...  \n",
       "4  /teamspace/studios/this_studio/.cache/kagglehu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = \"/teamspace/studios/this_studio/.cache/kagglehub/datasets/magdawjcicka/emotic/versions/1/annots_arrs/annot_arrs_train.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"Number of columns:\", len(df.columns))\n",
    "print(\"Columns:\\n\", df.columns.tolist())\n",
    "\n",
    "print(\"\\nHEAD:\\n\", df.head(10))\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BASE_PATH = \"/teamspace/studios/this_studio/.cache/kagglehub/datasets/magdawjcicka/emotic/versions/1\"\n",
    "ANNOT_PATH = os.path.join(BASE_PATH, \"annots_arrs\")\n",
    "CROP_PATH = os.path.join(BASE_PATH, \"img_arrs\")\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(ANNOT_PATH, \"annot_arrs_train.csv\"))\n",
    "val_df   = pd.read_csv(os.path.join(ANNOT_PATH, \"annot_arrs_val.csv\"))\n",
    "test_df  = pd.read_csv(os.path.join(ANNOT_PATH, \"annot_arrs_test.csv\"))\n",
    "\n",
    "cols = [\"Crop_name\", \"Valence\", \"Arousal\"]\n",
    "train_df = train_df[cols]\n",
    "val_df   = val_df[cols]\n",
    "test_df  = test_df[cols]\n",
    "\n",
    "train_df[\"img_path\"] = train_df[\"Crop_name\"].apply(lambda x: os.path.join(CROP_PATH, x))\n",
    "val_df[\"img_path\"]   = val_df[\"Crop_name\"].apply(lambda x: os.path.join(CROP_PATH, x))\n",
    "test_df[\"img_path\"]  = test_df[\"Crop_name\"].apply(lambda x: os.path.join(CROP_PATH, x))\n",
    "\n",
    "print(\"Train:\", len(train_df))\n",
    "print(\"Val:\", len(val_df))\n",
    "print(\"Test:\", len(test_df))\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Valence ---\n",
      "MAE: 1.0139\n",
      "MSE: 1.6762\n",
      "RMSE: 1.2947\n",
      "\n",
      "--- Arousal ---\n",
      "MAE: 0.9059\n",
      "MSE: 1.2943\n",
      "RMSE: 1.1377\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"/teamspace/studios/this_studio/Project_Affect/checkpoints/convnext_test_predictions.csv\")  \n",
    "\n",
    "df['diff_valence'] = df['pred_valence'] - df['true_valence']\n",
    "df['diff_arousal'] = df['pred_arousal'] - df['true_arousal']\n",
    "\n",
    "stats = {\n",
    "    \"Valence\": {\n",
    "        \"MAE\": df['diff_valence'].abs().mean(),\n",
    "        \"MSE\": (df['diff_valence']**2).mean(),\n",
    "        \"RMSE\": np.sqrt((df['diff_valence']**2).mean())\n",
    "    },\n",
    "    \"Arousal\": {\n",
    "        \"MAE\": df['diff_arousal'].abs().mean(),\n",
    "        \"MSE\": (df['diff_arousal']**2).mean(),\n",
    "        \"RMSE\": np.sqrt((df['diff_arousal']**2).mean())\n",
    "    }\n",
    "}\n",
    "\n",
    "for key, val in stats.items():\n",
    "    print(f\"\\n--- {key} ---\")\n",
    "    for k, v in val.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
